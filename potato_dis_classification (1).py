# -*- coding: utf-8 -*-
"""Potato_Dis_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eHcQ6_d27dp2z1F6zHV3cx_sh6WmgI-B
"""

# Step 1: Upload the zipped PlantVillage folder
# from google.colab import files
# uploaded = files.upload()

# Import Required Libraries
import tensorflow as tf
from tensorflow.keras import models, layers
import matplotlib.pyplot as plt
import numpy as np
import os
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.utils.class_weight import compute_class_weight

# Step 2: Extract the ZIP file
import zipfile
import os

zip_file = "Potato.zip"  # Change this if your file name is different
extract_folder = "/content/Potato"

with zipfile.ZipFile(zip_file, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

|# Step 3: Load images into a dataset variable
import tensorflow as tf

dataset = tf.keras.preprocessing.image_dataset_from_directory(
    extract_folder,
    seed=123,
    shuffle=True,
    image_size=(256, 256),  # Resize images to (256x256)
    batch_size=32  # Define batch size
)



# Step 4: Check class names (should print: ['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy'])
print("Class Names:", dataset.class_names)

# Step 5: Check a sample batch of images and labels
for images, labels in dataset.take(1):
    print("Image batch shape:", images.shape)
    print("Label batch shape:", labels.shape)

# Set Constants
BATCH_SIZE = 32
IMAGE_SIZE = 256
CHANNELS = 3
EPOCHS = 30  # Reduced from 50 for efficiency
DATA_DIR = "Potato"

# Load Dataset
dataset = tf.keras.preprocessing.image_dataset_from_directory(
    DATA_DIR,
    seed=123,
    shuffle=True,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE
)

# Get Class Names
class_names = dataset.class_names
print("Class Names:", class_names)

len(dataset)

"""here 68 is the number of batches and batch size is 32 so total length of dataset is 68*32"""

# Check class distribution
class_counts = {name: 0 for name in class_names}
for _, labels in dataset:
    for label in labels.numpy():
        class_counts[class_names[label]] += 1

print("Class Distribution:", class_counts)

# Visualize Sample Images
plt.figure(figsize=(10, 10))
for image_batch, labels_batch in dataset.take(1):
    for i in range(12):
        ax = plt.subplot(3, 4, i + 1)
        plt.imshow(image_batch[i].numpy().astype("uint8"))
        plt.title(class_names[labels_batch[i]])
        plt.axis("off")
plt.show()

# Load Dataset with Train-Validation-Test Split
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATA_DIR,
    validation_split=0.2,
    subset="training",
    seed=123,
    shuffle=True,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATA_DIR,
    validation_split=0.2,
    subset="validation",
    seed=123,
    shuffle=True,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE
)

# Creating a separate test dataset
test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATA_DIR,
    validation_split=0.2,  # 10% test set
    subset="validation",  # Second validation set acts as test
    seed=123,
    shuffle=True,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE
)

# Advanced Data Augmentation
data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.5),
    layers.RandomZoom(0.2),
    layers.RandomContrast(0.2),
    layers.RandomTranslation(0.1, 0.1),
    layers.RandomBrightness(0.2)
])

# Apply Data Augmentation to Train Dataset
train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))

# Cache, Shuffle, and Prefetch for Performance Optimization
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)

# Define CNN Model with Batch Normalization and Dropout
model = models.Sequential([
    # Rescaling
     tf.keras.layers.Rescaling(1./255, input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS)),

    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.5),
    layers.RandomZoom(0.2),
    layers.RandomContrast(0.2),
    layers.RandomTranslation(0.1, 0.1),
    layers.RandomBrightness(0.2),

  # input layer

    # Conv Block 1
    layers.Conv2D(32, (3,3), activation='relu'),
    layers.BatchNormalization(),
    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),

    # Conv Block 2
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.BatchNormalization(),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),

    # Conv Block 3
    layers.Conv2D(128, (3,3), activation='relu'),
    layers.BatchNormalization(),
    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),

    # Conv Block 4
    layers.Conv2D(256, (3,3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2,2)),

    # Global Average Pooling instead of Flatten
    layers.GlobalAveragePooling2D(),   # or Flatten()

    # Dense Layer
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),                                   # Dropout to prevent overfitting (regularization)
    layers.Dense(len(class_names), activation='softmax')  # Output Layer
])

# gemini


def build_improved_cnn(image_size, channels, num_classes):
    model = models.Sequential([
        # Data Augmentation Layer (applied first)
        layers.RandomFlip("horizontal_and_vertical", input_shape=(image_size, image_size, channels)),
        layers.RandomRotation(0.2),  # Reduced rotation
        layers.RandomZoom(0.1),      # Reduced zoom
        layers.RandomContrast(0.1),  # Reduced contrast
        layers.RandomTranslation(0.05, 0.05), # Reduced translation
        layers.RandomBrightness(0.1), # Reduced brightness

        # Rescaling (after augmentation for consistency)
        tf.keras.layers.Rescaling(1./255),

        # Conv Block 1
        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
        layers.MaxPooling2D((2, 2),strides=2),
        layers.Dropout(0.2),  # Add dropout after pooling

        # Conv Block 2
        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),  # Increase dropout

        # Conv Block 3
        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.4),  # Further increase dropout

        # Conv Block 4
        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.5),

        # Global Average Pooling
        layers.GlobalAveragePooling2D(),

        # Dense Layers
        layers.Dense(512, activation='relu'), # Increased units
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    return model

# Example usage:
IMAGE_SIZE = 128  # Or your desired size
CHANNELS = 3     # For RGB images
num_classes = len(class_names) # Assuming class_names is defined

improved_model = build_improved_cnn(IMAGE_SIZE, CHANNELS, num_classes)
improved_model.summary()

# Model Summary
model.summary()

# Early Stopping

# from tensorflow.keras.callbacks import EarlyStopping

# early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Compile the Model - we tll the model that which optimizer (gradient descent) and loss function we are going to use.
model.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)

# Train the Model

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    class_weight=class_weight_dict,  # Apply Class Weights
    callbacks=[lr_callback]  # Apply Learning Rate Scheduler
)

# weights and biases of first layer
model.layers[0].get_weights()

# Evaluate on Test Dataset
test_loss, test_accuracy = model.evaluate(test_ds)
print(f"Test Accuracy: {test_accuracy*100:.2f}%")

# Plot Training and Validation Metrics
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(range(EPOCHS), acc, label='Training Accuracy')
plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(EPOCHS), loss, label='Training Loss')
plt.plot(range(EPOCHS), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

# Confusion Matrix
y_true = []
y_pred = []
for images, labels in test_ds:
    predictions = model.predict(images)
    y_pred.extend(tf.argmax(predictions, axis=1).numpy())
    y_true.extend(labels.numpy())

cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# Save the Model
model.save("potato_disease_classifier.h5")
print("Model saved successfully!")

# Run prediction on a sample image

import numpy as np
for images_batch, labels_batch in test_ds.take(1):

    first_image = images_batch[0].numpy().astype('uint8')
    first_label = labels_batch[0].numpy()

    print("first image to predict")
    plt.imshow(first_image)
    print("actual label:",class_names[first_label])

    batch_prediction = model.predict(images_batch)
    print("predicted label:",class_names[np.argmax(batch_prediction[0])])

# Write a function for inference
In [45]: def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())
    img_array = tf.expand_dims(img_array, 0)
    predictions = model.predict(img_array)
    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2)
    return predicted_class, confidence

# Now run inference on few sample images

plt.figure(figsize=(15, 15))

for images, labels in test_ds.take(1):  # Take one batch of images
    for i in range(9):  # Display 9 images
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))

        # Get prediction
        predicted_class, confidence = predict(model, images[i].numpy())
        actual_class = class_names[labels[i]]

        # Corrected plt.title()
        plt.title(f"Actual: {actual_class}\nPredicted: {predicted_class}\nConfidence: {confidence:.2f}")

        plt.axis("off")  # Hide axis

plt.show()  # Display the plot

