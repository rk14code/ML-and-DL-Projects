# -*- coding: utf-8 -*-
"""Laptop Price Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10sVNQRiDJcWT8w4r6DvF-PYdPA_vXkKf
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv('laptop_data.csv')

df.head()

df.shape

df.info()

df.describe()   # 5 number summary

# checking for the duplicated rows
df.duplicated().sum()
# No two or more than two rows are same.

# checking for any missing value in any column
df.isnull().sum()
# there is no missing value in any column

df.drop(columns=['Unnamed: 0'],inplace=True)

df['Ram']=df['Ram'].str.replace('GB','')
df['Weight']=df['Weight'].str.replace('kg','')
df.rename(columns={'Inches': 'Size'},inplace=True)

df.head()

# Still Ram and Weight are object so we have to change in integer and float resp.
df['Ram']=df['Ram'].astype('int32')
df['Weight']=df['Weight'].astype('float32')

df.info()

"""## EDA"""

sns.histplot(df['Price'],bins=40,kde=True)

''' this gives a (histogram) graph of distribution of price data, we can clearly observe that the histogram is right skewed data means
meaning most prices are concentrated towards the lower range (between 0 and 100,000), with a long tail extending towards higher prices (over 100,000).
 The peak of the distribution is between 10,000 and 1,00,000, indicating that a large number of prices fall within this range.'''

sns.distplot(df['Price'])

sns.boxplot(x=df['Price'])

high_price_laptops = df[df['Price'] >= 150000]
high_price_laptops

"""## Gaming and Workstation laptop prices are higher and out of whiskers of box plot."""



print(df['Company'].value_counts())
df['Company'].value_counts().plot(kind='bar')

"""###Dell, Lenovo, and HP dominate the market with a large number of products, indicating their extensive product lines and strong market presence.
###Asus, Acer, MSI, Toshiba, and Apple have a moderate range of products.
### Several smaller brands (like Samsung, Razer, and others) have a limited presence, suggesting they target niche markets or have smaller product portfolios.
### This graph highlights how certain brands, particularly Dell, Lenovo, and HP, offer significantly more products than others, reflecting their market dominance.
"""

sns.barplot(x=df['Company'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

filtered_df =df[df['Company'].isin(['Dell','Lenovo','HP','Asus','Acer','MSI','Toshiba','Apple','Samsung','Razer',
'Mediacom','Microsoft','Xiaomi','Vero','Chuwi','Google','Fujitsu','LG','Huawei'])]

# Group by Company and calculate statistics
result = filtered_df.groupby('Company')['Price'].agg(['max', 'min', 'mean', 'median', 'std'])

# Display the result
print(result)

"""###  here are the conclusions a statistician might draw:

1. **Variation in Price Across Companies:**
Companies like Razer, Asus, and HP have the highest maximum prices, suggesting they offer premium laptops.
Companies like Vero, Fujitsu, and Mediacom have the lowest maximum prices, indicating they target budget-conscious consumers.
2. **Price Stability (Standard Deviation):**
Razer has a high standard deviation (99,100), indicating significant price variation in its offerings, likely due to a wide range of product lines from budget to high-end.
Vero has a low standard deviation (1,546), suggesting consistent pricing with limited variety in models.
3. **Median vs Mean Analysis:**
Companies like Apple and Microsoft have their median prices close to the mean, indicating relatively symmetrical price distributions.
Companies like Asus and HP have medians lower than their means, which may indicate a right-skewed distribution, where a few expensive models pull the mean upwards.
4. **Market Segmentation:**
Razer and Asus focus heavily on high-end gaming or performance laptops due to their high maximum prices and means.
Mediacom, Fujitsu, and Vero cater to the budget segment, as seen in their low mean prices.
5. **Outliers:**
The high standard deviation for Razer and Asus suggests potential outliers in the dataset. High-priced models could significantly affect their statistics.
6. **Diversity in Pricing:**
HP, Lenovo, and Dell have moderate means and medians, suggesting they offer a balanced mix of budget, mid-range, and premium laptops.
7. **Niche vs General Markets:**
Companies like Google and Huawei have narrower ranges of prices (relatively small standard deviation), suggesting they target specific segments of the market (e.g., Chromebooks or premium devices).
**Recommendations:**
For High-End Buyers: Look into brands like Razer, Asus, or HP.
For Budget Buyers: Consider Mediacom, Fujitsu, or Vero.
For Consistent Quality: Companies with lower standard deviations like Vero or Google could be a safer choice for predictable pricing.
These insights could guide decision-making for customers, manufacturers, and market analysts alike.
"""

print(df['TypeName'].value_counts())
df['TypeName'].value_counts().plot(kind='bar')

"""## Bar graph shows the distribution of different laptop types across several categories.
### 1.) Notebooks dominate the market, with more than 700 occurrences, significantly more than any other category. This indicates that notebooks are the most common and popular laptop type, likely due to their general-purpose usage,budget range(especially for students), affordability, and wide availability.
### 2.) Gaming laptops and Ultrabooks have similar numbers, both around 200 occurrences. Gaming laptops and Ultrabooks are popular for more specialized needs, such as high performance and portability.
### 3.) 2 in 1 Convertibles have a moderate presence, indicating a growing interest in versatile, hybrid devices.
### 4.) Workstations and Netbooks have the smallest shares, catering to more niche or declining markets.
"""

sns.barplot(x=df['TypeName'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

"""## This bar graph compares the average prices of different laptop types (TypeName) with error bars showing the price variation (standard deviation).
### Workstations have the highest average price, exceeding 120,000. This is expected as workstations are typically high-performance machines designed for specialized tasks like video editing, 3D rendering, or data science, which require powerful hardware components.

### Ultrabooks and Gaming laptops are both priced around 80,000 to 100,000.Ultrabooks are premium devices that emphasize portability, design, and performance.Gaming laptops require advanced hardware (e.g., high-end GPUs) for gaming, which drives up their price.

### 2 in 1 Convertible laptops, priced at around 70,000, are moderately expensive. These devices offer the versatility of functioning as both laptops and tablets, appealing to users looking for flexible, hybrid devices.

### Notebooks and Netbooks have the lowest average prices, with Notebooks around 50,000. Notebooks are general-purpose devices, while Netbooks are smaller, less powerful laptops designed for lightweight tasks, hence the lower pricing.
"""

filtered_df =df[df['TypeName'].isin([ 'Notebook', 'Gaming', 'Ultrabook','2 in 1 Convertible', 'Workstation'])]

# Group by Company and calculate statistics
result = filtered_df.groupby('TypeName')['Price'].agg(['max', 'min', 'mean', 'median', 'std'])

# Display the result
print(result)

"""### Here are the conclusions a statistician might draw from this data :

**1. Price Range by Laptop Type:**
Gaming laptops have the widest price range, with the highest maximum price (₹3,24,954.72) and a significant gap between the maximum and minimum, showing that gaming laptops vary greatly in price.
Notebooks are the most affordable, with the lowest average price (₹41,669.15) and the smallest minimum price (₹10,442.88), making them ideal for budget-conscious buyers.
Workstations are the most expensive on average (₹1,21,497.53), reflecting their specialized, high-performance use cases.

**2. Price Consistency:**
Ultrabooks have a smaller standard deviation (₹26,075.36), indicating their prices are relatively consistent, catering to a specific audience (likely professionals).
Notebooks also have lower price variability, emphasizing affordability and a narrow focus on budget and mid-range options.
Gaming laptops have the highest standard deviation (₹43,379.21), showing that prices vary a lot depending on specs and brand.

**3. Target Audience:**
2-in-1 Convertibles and Ultrabooks are priced higher on average, targeting professionals or users looking for premium features like portability and versatility.
Notebooks are ideal for general-purpose users with limited budgets.
Workstations cater to niche markets like engineers, designers, or data scientists who need high-performance machines.

**4. Median vs Mean:**
For most laptop types, the median price is slightly lower than the mean price, suggesting a few expensive models pull the average price higher.
Summary:

***Budget Buyers:*** Look for Notebooks for the best value.

***Professionals:*** Consider Ultrabooks or 2-in-
1 Convertibles for portability and high-end features.

***Gamers:*** Be ready to pay more for Gaming laptops, but know they vary widely in price.

***Power Users:*** Opt for Workstations, but expect a higher price tag due to their performance focus.

This data highlights how different laptop types cater to specific user needs and budgets, with notable price differences based on features and functionality.
"""

print(df['Size'].value_counts())
df['Size'].value_counts().plot(kind='bar')

"""#### Maximum laptops are of size 15.6 inches i.e. 665.
 #### Laptops having size of 17.3, 13.3, 14 inches have 164 & 197 resp.
 #### And laptops having different size vary from 1 to 50.
"""

sns.histplot(df['Size'],kde=True)

sns.distplot(df['Size'])
plt.show()

sns.scatterplot(x=df['Size'],y=df['Price'])

"""### 1.) Positive Correlation: There's a noticeable upward trend in prices as the size of the laptop increases.

### 2.) Price Variability: Laptops in the 13 to 15-inch range show a wide range of prices. This suggests that there are various models within this size range, including both budget and premium options.

### 3.) Larger Sizes (16 to 18 inches): Laptops(mainly gaming laptops or workstations) with screen sizes around 16 inches and above appear to have generally higher prices, with many exceeding 150,000.

### 4.) Smaller Sizes (10-12 inches): Smaller laptops (below 13 inches) are generally lower priced. These are likely netbooks or ultraportables

"""

df['ScreenResolution'].value_counts()

"""# Feature Engineering"""

df['Touchscreen'] = df['ScreenResolution'].apply(lambda x:1 if 'Touchscreen' in x else 0)

df['Touchscreen'].value_counts()

"""### There are 1111 (85.3%) touchscreen and 192 (14.7%) non-touchscreen laptops"""

df['Touchscreen'].value_counts().plot(kind='pie',
                                      autopct='%1.1f%%',  # Display percentages
                                      explode=[0.1, 0] ,    # Explode first slice
                                      shadow=True,                # Add shadow for better aesthetics
                                      startangle=90 )             # Start the pie chart at 90 degrees

sns.barplot(x=df['Touchscreen'],y=df['Price'])

non_touchscreen_stats = df[df['Touchscreen'] == 0]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
touchscreen_stats = df[df['Touchscreen'] == 1]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])

# Display results

print("Laptops without Touchscreen:")
print(non_touchscreen_stats)

print("\nLaptops with Touchscreen:")
print(touchscreen_stats)

"""### On an average the price of touchscreen laptops are higher than non-touchscreen laptops."""

df['IPS'] = df['ScreenResolution'].apply(lambda x:1 if 'IPS' in x else 0)

df['IPS'].value_counts()

"""### There are 365 (28%) IPS displAy laptops and 938 (72%) non-IPS display laptops."""

df['IPS'].value_counts().plot(kind='pie',
                                      autopct='%1.1f%%',
                                      explode=[0.1, 0] ,
                                      shadow=True,
                                      startangle=90 )

sns.barplot(x=df['IPS'],y=df['Price'])

non_ips_stats = df[df['IPS'] == 0]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
ips_stats = df[df['IPS'] == 1]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])

# Display results
print("Laptops without IPS:")
print(non_ips_stats)

print("\nLaptops with IPS:")
print(ips_stats)

"""### On an average Laptops with IPS displays tend to have higher prices compared to laptops without IPS displays. This could be due to the enhanced display quality and viewing angles."""

new = df['ScreenResolution'].str.split('x',n=1,expand=True)
new

df['X_res'] = new[0]
df['Y_res'] = new[1]

df.sample(5)

df['X_res'] = df['X_res'].str.replace(',','').str.findall(r'(\d+\.?\d+)').apply(lambda x:x[0])
df['X_res']

df['X_res'] = df['X_res'].astype('int')
df['Y_res'] = df['Y_res'].astype('int')
df['Y_res']

df.sample(5)

df.info()

# Select only numeric columns and then calculate the correlation
numeric_df = df.select_dtypes(include=['float', 'int'])
price_corr = numeric_df.corr()['Price']
print(price_corr)

"""### there is a positive correlation between X_res/Y_res and  price."""

df['PPI'] = (((df['X_res']**2) + (df['Y_res']**2))**0.5/df['Size']).astype('float')

numeric_df = df.select_dtypes(include=['float', 'int'])
price_corr = numeric_df.corr()['Price']
print(price_corr)

"""## we created a new column i.e. PPI with the help of ScreenResolution, X_res and Y_res columns and we can see that there is a positive correlation b/w PPI and price of Laptops.

### Now, we don't need that much of ScreenResolution, X_res and Y_res columns,so we will drop these three columns.
"""

df.drop(columns=['ScreenResolution'],inplace=True)

df.drop(columns=['Size','X_res','Y_res'],inplace=True)

df.sample(5)

df['Cpu'].value_counts()

df['Cpu Name'] = df['Cpu'].apply(lambda x:" ".join(x.split()[0:3]))

df.sample(5)

def fetch_processor(text):
    if text == 'Intel Core i7' or text == 'Intel Core i5' or text == 'Intel Core i3':
        return text
    else:
        if text.split()[0] == 'Intel':
            return 'Other Intel Processor'
        else:
            return 'AMD Processor'

df['Cpu brand'] = df['Cpu Name'].apply(fetch_processor)

df.sample(5)

df['Cpu brand'].value_counts()

"""###  Intel CPUs, with Intel Core i7 (527 or 40%) and Intel Core i5 (423 or 32%) being the most popular choices, suggesting a focus on mid- to high-performance machines (gaming or business). Other Intel processors (154 or 12%) and Intel Core i3 (136 or 10%) are less represented, indicating lower demand for entry-level or less common Intel models. AMD processors are significantly underrepresented (63 or 5%), possibly showing a market preference for Intel or a dataset bias. The data highlights Intel's dominance in this segment, with limited competition from AMD."""

df['Cpu brand'].value_counts().plot(kind='bar')

df['Cpu brand'].value_counts().plot(kind='pie',
                                      autopct='%1.1f%%',
                                      explode=[0.05, 0.05, 0.05, 0.05, 0.05] ,
                                      shadow=True,
                                      startangle=90 )

sns.barplot(x=df['Cpu brand'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

""" ### Intel Core i7 CPUs have the highest average price, which is typically used in high-performance laptops or desktops for tasks such as gaming, video editing, or software development.
### Intel Core i5 processors have a relatively high price but are lower than Core i7. They offer a balance of performance and cost.
### The category of Other Intel Processors has a moderate price point, typically representing more affordable and less powerful processors.
### AMD processors have lower average prices compared to all Intel processors. This suggests that AMD's positioning in the market is aimed at providing budget-friendly or value-based options, appealing to cost-conscious consumers.
"""

filtered_df =df[df['Cpu brand'].isin(['Intel Core i7', 'Intel Core i5', 'Intel Core i3', 'Other Intel Processor', 'AMD Processor'])]

# Group by Company and calculate statistics
result = filtered_df.groupby('Cpu brand')['Price'].agg(['max', 'min', 'mean', 'median', 'std'])

# Display the result
print(result)

df.drop(columns=['Cpu','Cpu Name'],inplace=True)

df.sample(5)

df['Ram'].value_counts()

sns.histplot(df['Ram'], color='lightgreen', edgecolor='black')

sns.distplot(df['Ram'], color='blue')

df['Ram'].value_counts().plot(kind='bar')

"""

*   **Most common RAM value:** The most common RAM value is 8 GB, with a significantly higher count compared to other values.

*  **Decreasing frequency:** As the RAM values increase, their frequency generally decreases. This suggests that fewer devices have higher RAM capacities.
*  **Concentration in lower RAM ranges:** The majority of devices seem to have RAM values between 2 GB and 16 GB, with a significant concentration around 8 GB.


"""

df['Ram'].value_counts().plot(kind='pie',autopct='%1.1f%%', shadow=True)

sns.barplot(x=df['Ram'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

"""

*   The graph shows a clear positive correlation between RAM and price. As the RAM capacity increases, the average price also increases.

*   However, it's important to note that the error bars indicate some variability in price within each RAM category. This suggests that other factors besides RAM, such as brand, storage capacity, processor type, and additional features, can also influence the price of a device.

"""

RAM_2GB_Laptops = df[df['Ram'] == 2]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
RAM_4GB_Laptops = df[df['Ram'] == 4]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
RAM_6GB_Laptops = df[df['Ram'] == 6]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
RAM_8GB_Laptops = df[df['Ram'] == 8]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
RAM_12GB_Laptops = df[df['Ram'] == 12]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
RAM_16GB_Laptops = df[df['Ram'] == 16]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
RAM_24GB_Laptops = df[df['Ram'] == 24]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
RAM_32GB_Laptops= df[df['Ram'] == 32]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
RAM_64GB_Laptops = df[df['Ram'] == 64]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])

# Display results

print("RAM_2GB_Laptops :")
print(RAM_2GB_Laptops )

print("\nRAM_4GB_Laptops :")
print(RAM_4GB_Laptops )

print("\nRAM_6GB_Laptops :")
print(RAM_6GB_Laptops )

print("\nRAM_8GB_Laptops :")
print(RAM_8GB_Laptops )

print("\nRAM_12GB_Laptops :")
print(RAM_12GB_Laptops )

print("\nRAM_16GB_Laptops :")
print(RAM_16GB_Laptops )

print("\nRAM_24GB_Laptops :")
print(RAM_24GB_Laptops )

print("\nRAM_32GB_Laptops :")
print(RAM_32GB_Laptops )

print("\nRAM_64GB_Laptops :")
print(RAM_64GB_Laptops )

df['Memory'].value_counts()

for i in df['Memory'].unique():
  print(i)

df['Memory'] = df['Memory'].astype(str).replace('\.0', '', regex=True)
df["Memory"] = df["Memory"].str.replace('GB', '')
df["Memory"] = df["Memory"].str.replace('TB', '000')

for i in df['Memory'].unique():
  print(i)

new = df["Memory"].str.split("+", n = 1, expand = True)
new.sample(10)

for i in new:
 print(new)

df["first"]= new[0]

for i in df['first'].unique():
  print(i)

df["first"]=df["first"].str.strip()   # used to remove leading and trailing whitespace characters from the "first" column

df["second"]= new[1]

for i in df['second'].unique():
  print(i)

df["Layer1HDD"] = df["first"].apply(lambda x: 1 if "HDD" in x else 0)
df["Layer1SSD"] = df["first"].apply(lambda x: 1 if "SSD" in x else 0)
df["Layer1Hybrid"] = df["first"].apply(lambda x: 1 if "Hybrid" in x else 0)
df["Layer1Flash_Storage"] = df["first"].apply(lambda x: 1 if "Flash Storage" in x else 0)

df['first'] = df['first'].str.replace(r'\D', '', regex=True)   # used to remove all non-digit characters from the "first" column

for i in df['first'].unique():
  print(i)

df["second"].fillna("0", inplace = True)    # used to replace missing values(NaN or None) in the "second" column with the value "0".

df["Layer2HDD"] = df["second"].apply(lambda x: 1 if "HDD" in x else 0)
df["Layer2SSD"] = df["second"].apply(lambda x: 1 if "SSD" in x else 0)
df["Layer2Hybrid"] = df["second"].apply(lambda x: 1 if "Hybrid" in x else 0)
df["Layer2Flash_Storage"] = df["second"].apply(lambda x: 1 if "Flash Storage" in x else 0)

df['second'] = df['second'].str.replace(r'\D', '', regex=True)   # # used to remove all non-digit characters from the "second" column

for i in df['second'].unique():
  print(i)

df["first"] = df["first"].astype(int)
df["second"] = df["second"].astype(int)

df

df["HDD"]=(df["first"]*df["Layer1HDD"]+df["second"]*df["Layer2HDD"])
df["SSD"]=(df["first"]*df["Layer1SSD"]+df["second"]*df["Layer2SSD"])
df["Hybrid"]=(df["first"]*df["Layer1Hybrid"]+df["second"]*df["Layer2Hybrid"])
df["Flash_Storage"]=(df["first"]*df["Layer1Flash_Storage"]+df["second"]*df["Layer2Flash_Storage"])

df.sample(5)

df.drop(columns=['first', 'second', 'Layer1HDD', 'Layer1SSD', 'Layer1Hybrid',
       'Layer1Flash_Storage', 'Layer2HDD', 'Layer2SSD', 'Layer2Hybrid',
       'Layer2Flash_Storage'],inplace=True)

df.sample(10)

df.drop(columns=['Memory'],inplace=True)

"""FROM HERE **NOT IN CAMPUSX**"""

sns.distplot(df['HDD'])

sns.histplot(df['HDD'])

df['HDD'].value_counts().plot(kind='bar')

"""### The chart shows that most laptops no longer use HDDs (represented by an HDD size of 0), likely due to the shift towards SSDs. Among laptops with HDDs, 1 TB is the most popular size, followed by 500 GB. Larger sizes like 2 TB and smaller ones like 32 GB and 128 GB are rare. This indicates a clear trend toward SSDs replacing traditional HDDs, as SSDs are faster and more reliable."""

df['HDD'].value_counts().plot(kind='pie',autopct='%1.1f%%', shadow=True)

sns.barplot(x=df['HDD'],y=df['Price'])
plt.show()

HDD_0GB_Laptops = df[df['HDD'] == 0]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
HDD_32GB_Laptops = df[df['HDD'] == 32]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
HDD_128GB_Laptops = df[df['HDD'] == 128]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
HDD_500GB_Laptops = df[df['HDD'] == 500]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
HDD_1000GB_Laptops = df[df['HDD'] == 1000]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
HDD_2000GB_Laptops = df[df['HDD'] == 2000]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])

# Display results

print("HDD_0GB_Laptops  :")
print(HDD_0GB_Laptops  )

print("\nHDD_32GB_Laptops :")
print(HDD_32GB_Laptops)

print("\nHDD_128GB_Laptops  :")
print(HDD_128GB_Laptops)

print("\nHDD_500GB_Laptops  :")
print(HDD_500GB_Laptops )

print("\nHDD_1000GB_Laptops  :")
print(HDD_1000GB_Laptops  )

print("\nHDD_2000GB_Laptops  :")
print(HDD_2000GB_Laptops  )

sns.distplot(df['SSD'])

sns.histplot(df['SSD'])

"""### The most common value of SSD is 0 and 256, with a frequency of around 500. As the values increase, the frequency generally decreases. This suggests a right-skewed distribution, where most of the data points are concentrated towards the lower end of the range."""

df['SSD'].value_counts().plot(kind='bar')

df['SSD'].value_counts().plot(kind='pie',autopct='%1.1f%%', shadow=True)

sns.barplot(x=df['SSD'],y=df['Price'])
plt.show()

SSD_0GB_Laptops = df[df['SSD'] == 0]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_8GB_Laptops = df[df['SSD'] == 8]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_16GB_Laptops = df[df['SSD'] == 16]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_32GB_Laptops = df[df['SSD'] == 32]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_64GB_Laptops = df[df['SSD'] == 64]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_128GB_Laptops = df[df['SSD'] == 128]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_180GB_Laptops = df[df['SSD'] == 180]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_240GB_Laptops = df[df['SSD'] == 240]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_256GB_Laptops = df[df['SSD'] == 256]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_512GB_Laptops = df[df['SSD'] == 512]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_768GB_Laptops = df[df['SSD'] == 768]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_1000GB_Laptops = df[df['SSD'] == 1000]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])
SSD_1024GB_Laptops = df[df['SSD'] == 1024]['Price'].agg(['max', 'min', 'mean', 'median', 'std'])

# Display results

print("SSD_0GB_Laptops  :")
print(SSD_0GB_Laptops)

print("\nSSD_8GB_Laptops  :")
print(SSD_8GB_Laptops)

print("\nSSD_16GB_Laptops  :")
print(SSD_16GB_Laptops)

print("\nSSD_32GB_Laptops  :")
print(SSD_32GB_Laptops)

print("\nSSD_64GB_Laptops  :")
print(SSD_64GB_Laptops)

print("\nSSD_128GB_Laptops  :")
print(SSD_128GB_Laptops)

print("\nSSD_180GB_Laptops  :")
print(SSD_180GB_Laptops)

print("\nSSD_240GB_Laptops  :")
print(SSD_240GB_Laptops)

print("\nSSD_256GB_Laptops  :")
print(SSD_256GB_Laptops)

print("\nSSD_512GB_Laptops  :")
print(SSD_512GB_Laptops)

print("\nSSD_768GB_Laptops  :")
print(SSD_768GB_Laptops)

print("\nSSD_1000GB_Laptops  :")
print(SSD_1000GB_Laptops)

print("\nSSD_1024GB_Laptops  :")
print(SSD_1024GB_Laptops)

"""**UPTO THIS ONLY NOT IN CAMPUS X**"""

numeric_df = df.select_dtypes(include=['float', 'int'])
price_corr = numeric_df.corr()['Price']
print(price_corr)

"""The strongest factors influencing laptop price are RAM (0.743) and SSD (0.671), both showing a strong positive correlation, meaning laptops with more RAM and SSD tend to be more expensive. PPI (0.473) also has a moderate positive correlation, while IPS (0.252), Weight (0.210), and Touchscreen (0.191) show weak positive correlations. HDD (-0.096) and Flash Storage (-0.041) have slight negative correlations, indicating they do not significantly raise prices, and Hybrid (0.008) has almost no effect on price."""

df.drop(columns=['Hybrid','Flash_Storage'],inplace=True)  # we dropped it bcz we get the best results

df.sample(5)

df['Gpu'].value_counts()

df['Gpu brand'] = df['Gpu'].apply(lambda x:x.split()[0])  # extracting only the brand names from GPU

df.sample(5)

df['Gpu brand'].value_counts()

df = df[df['Gpu brand'] != 'ARM']

df['Gpu brand'].value_counts()

sns.histplot(df['Gpu brand'], kde=True)

sns.barplot(x=df['Gpu brand'],y=df['Price'])
plt.show()

sns.barplot(x=df['Gpu brand'],y=df['Price'],estimator='median')
plt.show()

filtered_df =df[df['Gpu brand'].isin([ 'Intel', 'AMD', 'Nvidia'])]

# Group by Company and calculate statistics
result = filtered_df.groupby('Gpu brand')['Price'].agg(['max', 'min', 'mean', 'median', 'std'])

# Display the result
print(result)

df.drop(columns=['Gpu'],inplace=True)

df.sample()

df['OpSys'].value_counts()

sns.histplot(df['OpSys'], kde=True)
plt.xticks(rotation='vertical')

sns.barplot(x=df['OpSys'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

"""* macOS shows the highest average price, indicating that laptops with macOS tend to be the most expensive.
* Laptops with Windows 10 and Mac OS X also tend to have higher average prices, but not as high as macOS.
* No OS, Linux, Android, and Chrome OS are associated with significantly lower average laptop prices, suggesting that these operating systems are often found on lower-cost devices.
* Windows 10 S and Windows 7 fall in between, having moderate price ranges, but there’s greater variability in price for Windows 10 S devices.

**what could be the possible reasons that windows 7 laptops have higher average price than windows 10 laptops, even though windows 10 is better operating system than windows 7 ?**

**Ans-**
* Business and Industrial Use: Some businesses or industries may have specific requirements for Windows 7, and laptops configured for these purposes may include high-performance components, driving up the price.

* Limited Availability: As Windows 7 is no longer actively supported or sold, laptops pre-installed with Windows 7 might be in limited supply, making them more expensive in niche markets where they are still required.

* Custom Enterprise Solutions: High-end enterprise laptops often come pre-installed with older operating systems like Windows 7 for custom software environments, leading to higher prices due to additional business features, support, and security.
"""

def cat_os(inp):
    if inp == 'Windows 10' or inp == 'Windows 7' or inp == 'Windows 10 S':
        return 'Windows'
    elif inp == 'macOS' or inp == 'Mac OS X':
        return 'Mac'
    else:
        return 'Others/No OS/Linux'

df['OS'] = df['OpSys'].apply(cat_os)

df.drop(columns=['OpSys'],inplace=True)

df.sample(5)

sns.barplot(x=df['OS'],y=df['Price'])
plt.show()

# Since weight is a continouus variable, we can't plot the bar plot.
sns.distplot(df['Weight'])

df

"""### Assumptions for Linear Regression :-
1.) Linear relationship between the independent and dependent variables.
* Linear relationship b/w continuous input variables and target variable i.e., (by using scatterplot)
"""



# gemini

categorical_features = ['Company','TypeName', 'Cpu brand','Gpu brand', 'OS']
numerical_features = ['Ram','Weight','PPI','HDD','SSD',]
# 1. Linearity (Scatter plots of numerical features vs. price)

num_numerical = len(numerical_features)
rows = (num_numerical + 2) // 3  # Calculate the number of rows needed
cols = min(num_numerical, 3)     # Use at most 3 columns

plt.figure(figsize=(15, 5 * rows))  # Adjust figure size for better readability

for i, feature in enumerate(numerical_features):
    plt.subplot(rows, cols, i + 1)
    sns.scatterplot(x=df[feature], y=df['Price'])
    plt.title(f'Price vs. {feature}')

plt.tight_layout()
plt.show()

"""### 2) No perfect multicollinearity"""

numerical_df = df.select_dtypes(include=['int','float'])
correlation_matrix = numerical_df.corr()
plt.figure(figsize=(10,10))
sns.heatmap(correlation_matrix, annot=True, square=True)
plt.title('Correlation Heatmap of Numerical Columns')
plt.show()

# the more lighter shade/colour, the stronger correlation between the features.

"""**Strong Positive Correlations:**
* SSD vs. Ram: laptops with more RAM are likely to also have SSDs.
* PPI vs. SSD: laptops with higher-resolution displays are more likely to have SSDs.

**Moderate Positive Correlations:**
* Ram vs. Weight: laptops with more RAM might be slightly heavier.
* PPI vs. Weight: laptops with higher-resolution displays might be slightly heavier.

**Weak Positive Correlations:**
* Touchscreen vs. Weight: a slight association between touchscreen features and slightly heavier laptops.
* IPS vs. Weight: A similar weak positive correlation is observed between IPS panels and weight.

**Negative Correlations:**
* HDD vs. SSD: laptops with SSDs are less likely to have HDDs.
* HDD vs. Ram: laptops with more RAM are less likely to have HDDs.

**Other correlations:**
* Most other correlations are relatively weak, indicating that the relationships between these features are not particularly strong.

**Overall:**
The heatmap reveals several significant relationships between the features. Notably, the strong positive correlations between SSD and both RAM and PPI suggest that laptops with high-performance configurations (more RAM and higher resolution) are more likely to have SSDs. Additionally, the negative correlations between HDD and both SSD and RAM highlight the trend towards replacing HDDs with SSDs in modern laptops.

**Key takeaways:**
* SSD is a key feature: SSDs are strongly associated with higher-performance laptops, as evidenced by their correlations with RAM and PPI.
HDD is becoming less common: HDDs are increasingly being replaced by SSDs, especially in laptops with higher-performance configurations.
Weight and performance: While there are some correlations between weight and performance-related features (RAM and PPI), these relationships are not particularly strong.

* This heatmap provides valuable insights for stakeholders (such as consumers or manufacturers) in understanding which features are most influential in the pricing of laptops. It also emphasizes the importance of RAM and SSDs as crucial selling points in the current market.
"""

df1=df.copy()

df1

import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor

# List of categorical columns
categorical_cols = ['Company', 'TypeName', 'Cpu brand', 'Gpu brand', 'OS']

# 1. One-hot encode categorical variables
df_encoded = pd.get_dummies(df1, columns=categorical_cols, drop_first=True)

# 2. Drop the dependent variable
X = df_encoded.drop(columns=['Price'])

# 3. Ensure all data is of float type (important for VIF)
X = X.astype(float)

# 4. Add constant for intercept
X_const = sm.add_constant(X)

# 5. Calculate VIF
vif_data = pd.DataFrame()
vif_data['Feature'] = X_const.columns
vif_data['VIF'] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]

# 6. Drop intercept from result
vif_data = vif_data[vif_data['Feature'] != 'const']

print(vif_data)

df_encoded

"""# All our features have VIF values around 1.0 to 1.01, which means:

* There is no significant multicollinearity among your independent variables.

* The predictors are almost linearly independent from one another.

* We are good to go with these features in our linear regression model.
"""

fig, a = plt.subplots(3, 2, figsize=(12, 12))
sns.boxplot(x=df['Ram'],ax=a[0][0])
sns.boxplot(x=df['Weight'],ax=a[0][1])
sns.boxplot(x=df['PPI'],ax=a[1][0])
sns.boxplot(x=df['HDD'],ax=a[1][1])
sns.boxplot(x=df['SSD'], ax=a[2][0])
sns.boxplot(x=df['Price'], ax=a[2][1])
plt.show()

high_ram_laptops = df[df['Ram'] > 10]
high_ram_laptops

heavy_weight_laptops = df[df['Weight'] > 3.5]
heavy_weight_laptops

high_ppi_laptops = df[df['PPI'] > 200]
high_ppi_laptops

high_ssd_laptops = df[df['SSD'] > 500]
high_ssd_laptops

high_price_laptops = df[df['Price'] >= 150000]
high_price_laptops



# Since our target column(Price) is skewed,so it can disturb machine learning algorithm therefore we will make it normal by applying log transformation.
# we did this also bcz our R2 score increased by 5%.
# During the prediction we will do opposite of log i.e. exponential.

sns.distplot(np.log(df['Price']))
plt.title('Distribution of Log-Transformed Prices')
plt.xlabel('Log(Price)')
plt.ylabel('Density')
plt.show()

x = df.drop(columns=['Price'])
y = np.log(df['Price'])

x

y

df

# Assuming you stored the original 'price' before scaling
price_std = df['Price'].std()

# from google.colab import files
# df.to_csv('laptop_new.csv', index=False)

# Download the file
# files.download('laptop_new.csv')

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=2)

X_train

"""# we can do also scaling, feature selection, grid search CV to get more precise R2 score and MAE."""

# To handle the categorical columns we have to apply one hot encoding(OHE), so we will use
# column transformer along with the scikit learn pipeline.

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error

from sklearn.linear_model import LinearRegression,Ridge,Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor,ExtraTreesRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor

df.info()

handle_unknown='ignore'

# Linear regression

step1 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand','Touchscreen', 'IPS', 'OS','Gpu brand']),
    ('scaler', StandardScaler(), ['PPI','Ram', 'Weight','HDD','SSD' ])
], remainder='passthrough')
                              # Leave the other columns (like categorical) unchanged
step2 = LinearRegression()

lr_pipeline = Pipeline([
    ('step1',step1),
    ('step2',step2)
])
lr_pipeline.fit(X_train,y_train)

y_pred = lr_pipeline.predict(X_test)

r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]           # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
LR_MSE = mean_squared_error(y_test, y_pred)
LR_RMSE = np.sqrt(LR_MSE)

print('R2 score:',r2)                                 # .807, .812
print('MAE:',mean_absolute_error(y_test,y_pred))      # .2101
print('Adjusted R2 score:', adj_r2)                   # .79
print('MSE:', LR_MSE)                                    # .0737
print('RMSE:', LR_RMSE)                                  # .2714

# Mean of original target variable (before log transform)
mean_price = df['Price'].mean()
print(mean_price)

# Convert to original scale
LR_MSE_original = (np.exp(LR_MSE) - 1) * (mean_price ** 2)
LR_RMSE_original = np.sqrt(LR_MSE_original)

print(f"MSE in original price units: {LR_MSE_original:.5f}")
print(f"RMSE in original price units: {LR_RMSE_original:.5f}")

# gemini

# Check Homoscedasticity of errors

residuals_lr = y_test - y_pred
fitted_values_lr = y_pred

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
sns.scatterplot(x=fitted_values_lr, y=residuals_lr)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel("Fitted Values")
plt.ylabel("Residuals")
plt.title("Residuals vs. Fitted Values (Linear Regression)")

"""X-axis: Predicted (fitted) values from the regression model.

Y-axis: Residuals (errors) = Actual value − Predicted value.

The red dashed line is the zero line (ideal residual mean).

* The variance of errors appears to be constant — a key assumption of linear regression is not violated here.

**If the plot showed:**

* A funnel shape (residuals spreading out or shrinking as fitted values increase) → this would indicate heteroscedasticity.

* A curve or trend → might indicate non-linearity.

* Outliers that are far from the red line → may need to be addressed.
"""

from statsmodels.stats.diagnostic import het_breuschpagan

# Step 1: Transform X_train using the pipeline step
X_transformed = lr_pipeline.named_steps['step1'].transform(X_train)  # replace 'step1' with actual step name (e.g., 'preprocessor')

# Step 2: Predict and calculate residuals
y_pred = lr_pipeline.predict(X_train)
residuals_lr = y_train - y_pred

# Step 3: Add constant to transformed X for Breusch-Pagan test
X_train_sm = sm.add_constant(X_transformed)

# Step 4: Perform Breusch-Pagan test
bp_test = het_breuschpagan(residuals_lr, X_train_sm)
bp_stat, bp_pvalue, f_stat, f_pvalue = bp_test

# Step 5: Print results
print(f'Breusch-Pagan Test Statistic: {bp_stat}')
print(f'p-value: {bp_pvalue}')
print(f'F-statistic: {f_stat}')
print(f'F p-value: {f_pvalue}')

if f_pvalue > 0.05:
    print("✅ Residuals have constant variance (Homoscedasticity).")
else:
    print("❌ Residuals do not have constant variance (Heteroscedasticity).")

print(X_train_sm.shape, residuals_lr.shape)

# and Normality of Errors

sm.qqplot(residuals_lr, line='s')
plt.title("Q-Q Plot of Residuals (Linear Regression)")
plt.tight_layout()
plt.show()

"""1.) X-axis: Theoretical quantiles from a normal distribution (what the residuals should look like if they were normal).

2.) Y-axis: Actual quantiles from your residuals (sample data).

3.) Red line: Ideal line if residuals follow a perfect normal distribution.

4.) Blue dots: Actual residual quantiles from your model.

**Interpretation:**
* The points lie fairly close to the red line, especially in the middle range of the data.

* There are small deviations at the tails (ends) — a few points at both ends curve away from the line.

***This means:***

🔹 The residuals are approximately normally distributed, which satisfies another key assumption of linear regression.

🔹 The slight curvature at the ends suggests minor skewness or a few outliers, but nothing major.

❌ What Would Be a Problem?
* If points deviate strongly from the red line (especially forming an S-shape or bow), then residuals are not normally distributed.

* This could affect confidence intervals and p-values from the model.


"""

from scipy.stats import shapiro

stat, p = shapiro(residuals_lr)
print('Shapiro-Wilk Test Statistic =', stat)
print('p-value =', p)

if p > 0.05:
    print(" residuals likely follow normal distribution.")
else:
    print("residuals are not normally distributed.")

sns.distplot(residuals_lr)

# 2. Autocorrelation Function (ACF) Plot
# The ACF plot shows the correlation between the residuals at different lags.
# Significant spikes outside the confidence interval (shaded area) indicate potential autocorrelation.
plt.figure(figsize=(10, 5))
sm.graphics.tsa.plot_acf(residuals_lr, lags=20, alpha=0.05)    # Adjust 'lags' as needed
plt.title("Autocorrelation Function (ACF) of Residuals")
plt.xlabel("Lag")
plt.ylabel("Autocorrelation")
plt.show()

# Durbin Watson Test

from statsmodels.stats.stattools import durbin_watson

# Run Durbin-Watson test
dw_stat = durbin_watson(residuals_lr)

print(f'Durbin-Watson statistic: {dw_stat}')

"""**dw_stat ≈ 2, we can confirm the assumption of independent errors.**

Test Statistic Range: 0 to 4

* dw_stat ~ 2 → No autocorrelation ✅

* dw_stat < 2 → Positive autocorrelation ❌

* dw_stat > 2 → Negative autocorrelation ❌


"""

# 4. Ljung-Box Test
# The Ljung-Box test is a statistical test for autocorrelation in the residuals.
# It tests the null hypothesis that there is no autocorrelation up to a certain number of lags.
# A small p-value (typically < 0.05) suggests that we reject the null hypothesis,
# indicating significant autocorrelation.

from statsmodels.stats.diagnostic import acorr_ljungbox

lb_test = acorr_ljungbox(residuals_lr, lags=[10], return_df=True) # Test for autocorrelation up to 10 lags
print("\nLjung-Box Test for Autocorrelation:")
print(lb_test)

# Interpretation of Ljung-Box Test Output:
# - lb_Q: The Ljung-Box test statistic.
# - lb_pvalue: The p-value of the Ljung-Box test.

if lb_test['lb_pvalue'].iloc[0] < 0.05:
    print("The Ljung-Box test suggests significant autocorrelation in the residuals.")
else:
    print("The Ljung-Box test does not suggest significant autocorrelation in the residuals.")

# Further analysis: You can test for different numbers of lags in the Ljung-Box test.

lb_test_multiple_lags = acorr_ljungbox(residuals_lr, lags=range(1, 11), return_df=True)
print("\nLjung-Box Test for Autocorrelation (Multiple Lags):")
print(lb_test_multiple_lags)

# Cross-validation for Linear Regression (to check overfitting)

from sklearn.model_selection import cross_val_score, KFold
cv = KFold(n_splits=10, shuffle=True, random_state=42)               # k = 10	10-Fold CV (most used in practice), Lower bias and good stability

cv_scores_lr = cross_val_score(lr_pipeline, x, y, cv=cv, scoring='neg_mean_squared_error')
print(f"Cross-validation MSE scores (Linear Regression): {-cv_scores_lr}")
LR_MSE_mean = cv_scores_lr.mean()
print(f"Mean Cross-validation MSE (Linear Regression): {-LR_MSE_mean:.5f}")

# Convert to original scale
LR_MSE_CV = (np.exp(-LR_MSE_mean) - 1) * (mean_price ** 2)
LR_RMSE_CV = np.sqrt(LR_MSE_CV)

print(f"MSE in original price units: {LR_MSE_CV:.5f}")
print(f"RMSE in original price units: {LR_RMSE_CV:.5f}")



# Decision Tree

step3 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand', 'IPS','Touchscreen']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'Weight'])
], remainder='passthrough')

step4 = DecisionTreeRegressor(max_depth=8)

dt_pipeline = Pipeline([
    ('step3',step3),
    ('step4',step4)
])

dt_pipeline.fit(X_train,y_train)

y_pred = dt_pipeline.predict(X_test)

r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]           # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
DT_MSE = mean_squared_error(y_test, y_pred)
DT_RMSE = np.sqrt(DT_MSE)

print('R2 score:',r2)                                 # .8520
print('MAE:',mean_absolute_error(y_test,y_pred))      # .1762
print('Adjusted R2 score:', adj_r2)                   # .8423
print('MSE:', DT_MSE)                                    # .0566
print('RMSE:', DT_RMSE)                                  # .2379

# Cross-validation for Decision Tree (to check overfitting)

cv_scores_dt = cross_val_score(dt_pipeline, x, y, cv=cv, scoring='neg_mean_squared_error')
print(f"Cross-validation MSE scores (Decision Tree): {-cv_scores_dt}")
DT_MSE_mean = cv_scores_dt.mean()
print(f"Mean Cross-validation MSE (Linear Regression): {-DT_MSE_mean:.5f}")

# Convert to original scale
DT_MSE_CV = (np.exp(-DT_MSE_mean) - 1) * (mean_price ** 2)
DT_RMSE_CV = np.sqrt(DT_MSE_CV)

print(f"MSE in original price units: {DT_MSE_CV:.5f}")
print(f"RMSE in original price units: {DT_RMSE_CV:.5f}")

# Random Forest
step5 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand', 'IPS', 'Touchscreen']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'Weight'])
], remainder='passthrough')

step6 = RandomForestRegressor(n_estimators=100,
                              random_state=3,
                              max_samples=0.5,
                              max_features=0.75,
                              max_depth=15)

rf_pipeline = Pipeline([
    ('step5',step5),
    ('step6',step6)
])

rf_pipeline.fit(X_train,y_train)

y_pred = rf_pipeline.predict(X_test)


r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]           # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
RF_MSE = mean_squared_error(y_test, y_pred)
RF_RMSE = np.sqrt(RF_MSE)

print('R2 score:',r2)                                 # .8856
print('MAE:',mean_absolute_error(y_test,y_pred))      # .1599
print('Adjusted R2 score:', adj_r2)                   # .8781
print('MSE:', RF_MSE)                                    # .0437
print('RMSE:', RF_RMSE)                                  # .2091

# Cross-validation for Random Forest (to check overfitting)
cv_scores_rf = cross_val_score(rf_pipeline, x, y, cv=cv, scoring='neg_mean_squared_error')
print(f"Cross-validation MSE scores (Random Forest): {-cv_scores_rf}")
RF_MSE_mean = cv_scores_rf.mean()
print(f"Mean Cross-validation MSE (Linear Regression): {-RF_MSE_mean:.5f}")

# Convert to original scale
RF_MSE_CV = (np.exp(-RF_MSE_mean) - 1) * (mean_price ** 2)
RF_RMSE_CV = np.sqrt(RF_MSE_CV)

print(f"MSE in original price units: {RF_MSE_CV:.5f}")
print(f"RMSE in original price units: {RF_RMSE_CV:.5f}")

# Preprocessing (same as Random Forest)
step5_svm = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand', 'IPS', 'Touchscreen']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'Weight'])
], remainder='passthrough')

# SVR Model
step6_svm = SVR(kernel='rbf', C=100, epsilon=0.1)

# Create pipeline
svm_pipeline = Pipeline([
    ('step5', step5_svm),
    ('step6', step6_svm)
])

# Fit the model
svm_pipeline.fit(X_train, y_train)

# Predictions
y_pred_svm = svm_pipeline.predict(X_test)

# R² and Adjusted R²
r2_svm = r2_score(y_test, y_pred_svm)
n = X_test.shape[0]
p = X_test.shape[1]
adj_r2_svm = 1 - (((1 - r2_svm) * (n - 1)) / (n - p - 1))

# Errors
SVM_MSE = mean_squared_error(y_test, y_pred_svm)
SVM_RMSE = np.sqrt(SVM_MSE)
SVM_MAE = mean_absolute_error(y_test, y_pred_svm)

# Print evaluation metrics
print("R² Score:", r2_svm)
print("Adjusted R² Score:", adj_r2_svm)
print("MAE:", SVM_MAE)
print("MSE:", SVM_MSE)
print("RMSE:", SVM_RMSE)

# Cross-validation
cv_scores_svm = cross_val_score(svm_pipeline, x, y, cv=cv, scoring='neg_mean_squared_error')
print(f"Cross-validation MSE scores (SVM): {-cv_scores_svm}")
SVM_MSE_mean = cv_scores_svm.mean()
print(f"Mean Cross-validation MSE (SVM): {-SVM_MSE_mean:.5f}")

# Convert to original scale
SVM_MSE_CV = (np.exp(-SVM_MSE_mean) - 1) * (mean_price ** 2)
SVM_RMSE_CV = np.sqrt(SVM_MSE_CV)

print(f"MSE in original price units: {SVM_MSE_CV:.5f}")
print(f"RMSE in original price units: {SVM_RMSE_CV:.5f}")























































































# KNN

'''step7 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand', 'IPS','Touchscreen']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'Weight'])
], remainder='passthrough')

step8 = KNeighborsRegressor(n_neighbors=13)

knn_pipeline = Pipeline([
    ('step7',step7),
    ('step8',step8)
])
knn_pipeline.fit(X_train,y_train)

y_pred = knn_pipeline.predict(X_test)

r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]           # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
KNN_MSE = mean_squared_error(y_test, y_pred)
KNN_RMSE = np.sqrt(KNN_MSE)

print('R2 score:',r2)                                 # .7906
print('MAE:',mean_absolute_error(y_test,y_pred))      # .2034
print('Adjusted R2 score:', adj_r2)                   # .7769
print('MSE:', KNN_MSE)                                    # .0800
print('RMSE:', KNN_RMSE)                                  # .2829

# KNN

# Define the preprocessing steps
preprocessor = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand', 'IPS','Touchscreen']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'Weight'])
], remainder='passthrough')

# Initialize the KNN regressor (the number of neighbors will be set later)
knn = KNeighborsRegressor()

# Create the pipeline
knn_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('knn', knn)
])

# Determine the optimal number of neighbors using cross-validation
k_values = range(1, 31)
cv_scores = []

for k in k_values:
    knn_pipeline.set_params(knn__n_neighbors=k)
    scores = cross_val_score(knn_pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
    cv_scores.append(-scores.mean())

# Identify the optimal k
optimal_k = k_values[np.argmin(cv_scores)]
print(f"Optimal k: {optimal_k}")

# Set the optimal number of neighbors in the pipeline
knn_pipeline.set_params(knn__n_neighbors=optimal_k)

# Train the model on the training data
knn_pipeline.fit(X_train, y_train)

# Predict on the test data
y_pred = knn_pipeline.predict(X_test)

# Calculate evaluation metrics
r2 = r2_score(y_test, y_pred)
n = X_test.shape[0]  # Number of samples
p = X_test.shape[1]  # Number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)

# Print evaluation metrics
print(f"R² Score: {r2:.4f}")
print(f"Adjusted R² Score: {adj_r2:.4f}")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")

k_values = range(1, 31)
cv_scores = []

# Perform cross-validation for each k
for k in k_values:
    knn_pipeline.set_params(knn__n_neighbors=k)
    # Use negative mean squared error as the scoring metric
    scores = cross_val_score(knn_pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
    # Append the mean of the negative MSE scores
    cv_scores.append(-scores.mean())

# Plot the results
plt.figure(figsize=(10, 6))
plt.plot(k_values, cv_scores, marker='o')
plt.title('Elbow Method for Optimal k in KNN Regression')
plt.xlabel('Number of Neighbors (k)')
plt.ylabel('Mean Squared Error')
plt.xticks(k_values)
plt.grid(True)
plt.show()

# Identify the optimal k
optimal_k = k_values[np.argmin(cv_scores)]
print(f"Optimal k: {optimal_k}")

import numpy as np
import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Assuming 'df' is your DataFrame and 'Price' is the target variable
# Replace 'df' with your actual DataFrame variable
X = df.drop('Price', axis=1)
y = df['Price']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define categorical and numerical features
categorical_features = ['Company', 'TypeName', 'Cpu brand', 'OS', 'Gpu brand', 'IPS', 'Touchscreen']
numerical_features = ['PPI', 'Ram', 'HDD', 'SSD', 'Weight']

# Create the preprocessing pipeline
step7 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand', 'IPS','Touchscreen']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'Weight'])
], remainder='passthrough')

# Initialize the KNN regressor
step8 = KNeighborsRegressor()

# Create the full pipeline
knn_pipeline = Pipeline([
    ('step7',step7),
    ('step8',step8)
])

# Determine the optimal number of neighbors (k) using cross-validation
k_values = range(1, 31)
cv_scores = []

for k in k_values:
    knn_pipeline.set_params(knn__n_neighbors=k)
    scores = cross_val_score(knn_pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
    cv_scores.append(-scores.mean())

# Identify the optimal k
optimal_k = k_values[np.argmin(cv_scores)]
print(f"Optimal k: {optimal_k}")

# Update the pipeline with the optimal k
knn_pipeline.set_params(knn__n_neighbors=optimal_k)

# Fit the pipeline on the training data
knn_pipeline.fit(X_train, y_train)

# Predict on the test data
y_pred = knn_pipeline.predict(X_test)

# Calculate performance metrics
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

# Calculate Adjusted R-squared
n = X_test.shape[0]  # number of samples
p = X_test.shape[1]  # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Display the results
print(f"R2 score: {r2}")
print(f"Adjusted R2 score: {adj_r2}")
print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")

# Cross-validation for KNN (to check overfitting)
cv_scores_knn = cross_val_score(knn_pipeline, x, y, cv=cv, scoring='neg_mean_squared_error')
print(f"Cross-validation MSE scores (KNN): {-cv_scores_knn}")
KNN_MSE_mean = cv_scores_knn.mean()
print(f"Mean Cross-validation MSE (Linear Regression): {-KNN_MSE_mean:.5f}")

# Convert to original scale
KNN_MSE_CV = (np.exp(-KNN_MSE_mean) - 1) * (mean_price ** 2)
KNN_RMSE_CV = np.sqrt(KNN_MSE_CV)

print(f"MSE in original price units: {KNN_MSE_CV:.5f}")
print(f"RMSE in original price units: {KNN_RMSE_CV:.5f}")









































# ExtraTrees (Variation Of Random Forest)

step1 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'IPS', 'Weight', 'Touchscreen'])
], remainder='passthrough')

step3 = ExtraTreesRegressor(bootstrap=True,n_estimators=2000,
                              random_state=6,
                              max_samples=0.5,
                              max_features=0.75,
                              max_depth=10)

pipe = Pipeline([
    ('step1',step1),
    ('step3',step3)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]           # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)

print('R2 score:',r2)                                 # .8850
print('MAE:',mean_absolute_error(y_test,y_pred))      # .1615
print('Adjusted R2 score:', adj_r2)                   # .
print('MSE:', MSE)                                    # .
print('RMSE:', RMSE)

# Ridge Regression


step1 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand', 'IPS','Touchscreen']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'Weight'])
], remainder='passthrough')

step2 = Ridge(alpha=15)

pipe = Pipeline([
    ('step1',step1),
    ('step2',step2)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]           # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)

print('R2 score:',r2)                                 # .8127
print('MAE:',mean_absolute_error(y_test,y_pred))      # .2092
print('Adjusted R2 score:', adj_r2)                   # .
print('MSE:', MSE)                                    # .
print('RMSE:', RMSE)

# Lasso Regression

step1 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'IPS','OS','Gpu brand', 'Touchscreen']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'Weight',])
], remainder='passthrough')

step3 = Lasso(alpha=0.0007)

pipe = Pipeline([
    ('step1',step1),
    ('step3',step3)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]           # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)

print('R2 score:',r2)                                 # .8071
print('MAE:',mean_absolute_error(y_test,y_pred))      # .2111
print('Adjusted R2 score:', adj_r2)                   # .79
print('MSE:', MSE)                                    # .0737
print('RMSE:', RMSE)

# AdaBoost

step1 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'IPS', 'Weight', 'Touchscreen'])
], remainder='passthrough')

pipe = Pipeline([
    ('step1',step1),
    ('step3',step3)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]

      # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)

print('R2 score:',r2)                                 # .8006
print('MAE:',mean_absolute_error(y_test,y_pred))      # .2287
print('Adjusted R2 score:', adj_r2)                   # .
print('MSE:', MSE)                                    # .
print('RMSE:', RMSE)

# Gradient Boost

step1 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'IPS', 'Weight', 'Touchscreen'])
], remainder='passthrough')


step3 = GradientBoostingRegressor(n_estimators=300)

pipe = Pipeline([
    ('step1',step1),
    ('step3',step3)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]           # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)

print('R2 score:',r2)                                 # .8824
print('MAE:',mean_absolute_error(y_test,y_pred))      # .1594
print('Adjusted R2 score:', adj_r2)                   # .
print('MSE:', MSE)                                    # .
print('RMSE:', RMSE)

# XgBoost

step1 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'IPS', 'Weight', 'Touchscreen'])
], remainder='passthrough')


step3 = XGBRegressor(n_estimators=70,max_depth=5,learning_rate=0.25)

pipe = Pipeline([
    ('step1',step1),
    ('step3',step3)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]           # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)

print('R2 score:',r2)                                 # .8771
print('MAE:',mean_absolute_error(y_test,y_pred))      # .1626
print('Adjusted R2 score:', adj_r2)                   # .
print('MSE:', MSE)                                    # .
print('RMSE:', RMSE)

# Voting Regressor

from sklearn.ensemble import VotingRegressor,StackingRegressor

step1 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'IPS', 'Weight', 'Touchscreen'])
], remainder='passthrough')

rf = RandomForestRegressor(n_estimators=350,random_state=3,max_samples=0.5,max_features=0.75,max_depth=15)
gbdt = GradientBoostingRegressor(n_estimators=100,max_features=0.5)
xgb = XGBRegressor(n_estimators=25,learning_rate=0.3,max_depth=5)
et = ExtraTreesRegressor(n_estimators=100,random_state=3,max_samples=0.5,max_features=0.75,max_depth=10,bootstrap=True)

step3 = VotingRegressor([('rf', rf), ('gbdt', gbdt), ('xgb',xgb), ('et',et)],weights=[5,1,1,1])

pipe = Pipeline([
    ('step1',step1),
    ('step3',step3)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]           # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)

print('R2 score:',r2)                                 # .8899
print('MAE:',mean_absolute_error(y_test,y_pred))      # .1578
print('Adjusted R2 score:', adj_r2)                   # .
print('MSE:', MSE)                                    # .
print('RMSE:', RMSE)

# Stacking

from sklearn.ensemble import VotingRegressor,StackingRegressor

step1 = ColumnTransformer(transformers=[
    ('ohe', OneHotEncoder(sparse_output=False, drop='first'), ['Company', 'TypeName','Cpu brand', 'OS','Gpu brand']),
    ('scaler', StandardScaler(), ['PPI','Ram','HDD','SSD', 'IPS', 'Weight', 'Touchscreen'])
], remainder='passthrough')

estimators = [
    ('rf', RandomForestRegressor(n_estimators=350,random_state=3,max_samples=0.5,max_features=0.75,max_depth=15)),
    ('gbdt',GradientBoostingRegressor(n_estimators=100,max_features=0.5)),
    ('xgb', XGBRegressor(n_estimators=25,learning_rate=0.3,max_depth=5))
]

step3 = StackingRegressor(estimators=estimators, final_estimator=Ridge(alpha=100))

pipe = Pipeline([
    ('step1',step1),
    ('step3',step3)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

r2 = r2_score(y_test, y_pred)

# Calculating Adjusted R-squared
n = X_test.shape[0]           # number of samples
p = X_test.shape[1]           # number of features
adj_r2 = 1 - (((1 - r2) * (n - 1)) / (n - p - 1))

# Calculating MSE & (RMSE)
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)

print('R2 score:',r2)                                 # .8785
print('MAE:',mean_absolute_error(y_test,y_pred))      # .1670
print('Adjusted R2 score:', adj_r2)                   # .
print('MSE:', MSE)                                    # .
print('RMSE:', RMSE)

